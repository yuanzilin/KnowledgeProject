{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170651\n",
      "{'en': 'Go.', 'fr': 'Va !'}\n"
     ]
    }
   ],
   "source": [
    "f=open(\"fra.txt\",\"r\",encoding=\"utf-8\").readlines()\n",
    "en=[]\n",
    "fre=[]\n",
    "data=[]\n",
    "for l in f:\n",
    "    line=l.strip().split(\"\\t\")\n",
    "    tmp={}\n",
    "    tmp[\"en\"]=line[0]\n",
    "    tmp[\"fr\"]=line[1]\n",
    "    data.append(tmp)\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 它有3个列：input_ids、attention、labels，其中前两个列是tokenizer这个类的固有列，labels是预处理函数中加进去的一列\n",
    "train_size=int(len(data)*0.9)\n",
    "train_data=data[:train_size]\n",
    "val_data=data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"train.txt\",\"w\")\n",
    "for i in train_data:\n",
    "    f.write(str(i)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"val.txt\",\"w\")\n",
    "for i in val_data:\n",
    "    f.write(str(i)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# 分词，使用已经训练好的helsinki-NLP/opus-mt-en-ro来做翻译任务\n",
    "from transformers import AutoTokenizer\n",
    "model_checkpoint=\"Helsinki-NLP/opus-mt-en-ro\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_checkpoint,use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.source_lang=\"en_XX\"\n",
    "tokenizer.target_lang=\"fr_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把以上内容合并成预处理函数\n",
    "max_input_length=64\n",
    "max_target_length=64\n",
    "source_lang=\"en\"\n",
    "target_lang=\"fr\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs=[eval(ex)[source_lang] for ex in examples[\"text\"]]\n",
    "    targets=[eval(ex)[target_lang] for ex in examples[\"text\"]]\n",
    "    model_inputs=tokenizer(inputs,max_length=max_input_length,truncation=True)\n",
    "    # 为目标语言设置分词器\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels=tokenizer(targets,max_length=max_target_length,truncation=True)\n",
    "    model_inputs[\"labels\"]=labels[\"input_ids\"]\n",
    "    return model_inputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-220cc82d5924ef47\n",
      "Reusing dataset text (/home/ma-user/.cache/huggingface/datasets/text/default-220cc82d5924ef47/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
      "100%|██████████| 2/2 [00:00<00:00, 1113.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets=load_dataset(\"text\",data_files={\"train\":\"train.txt\",\"validation\":\"val.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 153585\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 17066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:16<00:00,  9.53ba/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  7.54ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets=raw_datasets.map(preprocess_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 153585\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 17066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ProxyError), entering retry loop.\n",
      "wandb: Network error (ProxyError), entering retry loop.\n",
      "wandb: Network error (ProxyError), entering retry loop.\n",
      "wandb: Network error (ProxyError), entering retry loop.\n",
      "wandb: Network error (ProxyError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 153585\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 17066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微调预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# 设定训练参数\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "batch_size=8\n",
    "args=Seq2SeqTrainingArguments(\n",
    "    \"test-translation\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3, # 至多保存的模型个数\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据收集器data collator，告诉trainer如何从预处理的输入数据中构造batch，我使用数据处理器DataCollatorForSeq2Seq\n",
    "# 将预处理的输入分batch再次处理后喂给模型\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator=DataCollatorForSeq2Seq(tokenizer,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully import metric\n"
     ]
    }
   ],
   "source": [
    "# 定义评估方法，使用bleu指标，利用metric.compute计算该指标对模型进行评估\n",
    "# 定义postprocess_text函数做一些数据后处理\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_metric\n",
    "metric=load_metric(\"sacrebleu\")\n",
    "print(\"successfully import metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds,labels):\n",
    "    preds=[pred.strip() for pred in preds]\n",
    "    labels=[[label.strip()] for label in labels]\n",
    "    return preds,labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds,labels=eval_preds\n",
    "    if isinstance(preds,tuple):\n",
    "        preds=preds[0]\n",
    "    decoded_preds=tokenizer.batch_decode(preds,skip_special_tokens=True)\n",
    "\n",
    "    # 如果labels=-100，说明这个label是无法编码的，应该用pad_token_id去进行填充\n",
    "    labels=np.where(labels!=-100,labels,tokenizer.pad_token_id)\n",
    "    decoded_labels=tokenizer.batch_decode(labels,skip_special_tokens=True)\n",
    "\n",
    "    # 把预测后的输出转成适合metric.compute输入的格式\n",
    "    print(\"type(decoded_preds)=\",type(decoded_preds))\n",
    "    print(\"type(decoded_labels)=\",type(decoded_labels))\n",
    "    decoded_preds,decoded_labels=postprocess_text(decoded_preds,decoded_labels)\n",
    "\n",
    "    result=metric.compute(predictions=decoded_preds,references=decoded_labels)\n",
    "    result={\"bleu\":result[\"score\"]}\n",
    "    \n",
    "    prediction_lens=[np.count_nonzero(pred!=tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"]=np.mean(prediction_lens)\n",
    "    result={k:round(v,4) for k,v in result.items()}\n",
    "    print(\"result is as follow============================\")\n",
    "    print(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 153585\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24000' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24000/24000 2:33:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>0.797258</td>\n",
       "      <td>40.478500</td>\n",
       "      <td>28.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.748112</td>\n",
       "      <td>42.054000</td>\n",
       "      <td>28.373400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.722455</td>\n",
       "      <td>42.839800</td>\n",
       "      <td>28.343800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.710104</td>\n",
       "      <td>43.079300</td>\n",
       "      <td>28.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.314800</td>\n",
       "      <td>0.706367</td>\n",
       "      <td>43.622100</td>\n",
       "      <td>28.369800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.701936</td>\n",
       "      <td>43.819400</td>\n",
       "      <td>28.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.699545</td>\n",
       "      <td>43.856200</td>\n",
       "      <td>28.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.271700</td>\n",
       "      <td>0.698904</td>\n",
       "      <td>44.060500</td>\n",
       "      <td>28.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.698022</td>\n",
       "      <td>44.235000</td>\n",
       "      <td>28.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.699177</td>\n",
       "      <td>44.337100</td>\n",
       "      <td>28.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-500\n",
      "Configuration saved in test-translation/checkpoint-500/config.json\n",
      "Model weights saved in test-translation/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-1000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-1000\n",
      "Configuration saved in test-translation/checkpoint-1000/config.json\n",
      "Model weights saved in test-translation/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-1500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-1500\n",
      "Configuration saved in test-translation/checkpoint-1500/config.json\n",
      "Model weights saved in test-translation/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-2000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-2000\n",
      "Configuration saved in test-translation/checkpoint-2000/config.json\n",
      "Model weights saved in test-translation/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 40.4785, 'gen_len': 28.4694}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-2500\n",
      "Configuration saved in test-translation/checkpoint-2500/config.json\n",
      "Model weights saved in test-translation/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-1000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-3000\n",
      "Configuration saved in test-translation/checkpoint-3000/config.json\n",
      "Model weights saved in test-translation/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-1500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-3500\n",
      "Configuration saved in test-translation/checkpoint-3500/config.json\n",
      "Model weights saved in test-translation/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-2000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-4000\n",
      "Configuration saved in test-translation/checkpoint-4000/config.json\n",
      "Model weights saved in test-translation/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-2500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-4500\n",
      "Configuration saved in test-translation/checkpoint-4500/config.json\n",
      "Model weights saved in test-translation/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-3000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 42.054, 'gen_len': 28.3734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-5000\n",
      "Configuration saved in test-translation/checkpoint-5000/config.json\n",
      "Model weights saved in test-translation/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-3500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-5500\n",
      "Configuration saved in test-translation/checkpoint-5500/config.json\n",
      "Model weights saved in test-translation/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-4000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-6000\n",
      "Configuration saved in test-translation/checkpoint-6000/config.json\n",
      "Model weights saved in test-translation/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-4500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-6500\n",
      "Configuration saved in test-translation/checkpoint-6500/config.json\n",
      "Model weights saved in test-translation/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-5000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-7000\n",
      "Configuration saved in test-translation/checkpoint-7000/config.json\n",
      "Model weights saved in test-translation/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-5500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 42.8398, 'gen_len': 28.3438}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-7500\n",
      "Configuration saved in test-translation/checkpoint-7500/config.json\n",
      "Model weights saved in test-translation/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-6000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-8000\n",
      "Configuration saved in test-translation/checkpoint-8000/config.json\n",
      "Model weights saved in test-translation/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-6500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-8500\n",
      "Configuration saved in test-translation/checkpoint-8500/config.json\n",
      "Model weights saved in test-translation/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-7000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-9000\n",
      "Configuration saved in test-translation/checkpoint-9000/config.json\n",
      "Model weights saved in test-translation/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-7500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-9500\n",
      "Configuration saved in test-translation/checkpoint-9500/config.json\n",
      "Model weights saved in test-translation/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-8000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 43.0793, 'gen_len': 28.4551}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-10000\n",
      "Configuration saved in test-translation/checkpoint-10000/config.json\n",
      "Model weights saved in test-translation/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-8500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-10500\n",
      "Configuration saved in test-translation/checkpoint-10500/config.json\n",
      "Model weights saved in test-translation/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-9000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-11000\n",
      "Configuration saved in test-translation/checkpoint-11000/config.json\n",
      "Model weights saved in test-translation/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-9500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-11500\n",
      "Configuration saved in test-translation/checkpoint-11500/config.json\n",
      "Model weights saved in test-translation/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-10000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-12000\n",
      "Configuration saved in test-translation/checkpoint-12000/config.json\n",
      "Model weights saved in test-translation/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-10500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 43.6221, 'gen_len': 28.3698}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-12500\n",
      "Configuration saved in test-translation/checkpoint-12500/config.json\n",
      "Model weights saved in test-translation/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-11000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-13000\n",
      "Configuration saved in test-translation/checkpoint-13000/config.json\n",
      "Model weights saved in test-translation/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-11500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-13500\n",
      "Configuration saved in test-translation/checkpoint-13500/config.json\n",
      "Model weights saved in test-translation/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-12000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-14000\n",
      "Configuration saved in test-translation/checkpoint-14000/config.json\n",
      "Model weights saved in test-translation/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-12500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 43.8194, 'gen_len': 28.322}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-14500\n",
      "Configuration saved in test-translation/checkpoint-14500/config.json\n",
      "Model weights saved in test-translation/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-13000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-15000\n",
      "Configuration saved in test-translation/checkpoint-15000/config.json\n",
      "Model weights saved in test-translation/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-13500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-15500\n",
      "Configuration saved in test-translation/checkpoint-15500/config.json\n",
      "Model weights saved in test-translation/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-14000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-16000\n",
      "Configuration saved in test-translation/checkpoint-16000/config.json\n",
      "Model weights saved in test-translation/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-14500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-16500\n",
      "Configuration saved in test-translation/checkpoint-16500/config.json\n",
      "Model weights saved in test-translation/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-15000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 43.8562, 'gen_len': 28.4313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-17000\n",
      "Configuration saved in test-translation/checkpoint-17000/config.json\n",
      "Model weights saved in test-translation/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-15500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-17500\n",
      "Configuration saved in test-translation/checkpoint-17500/config.json\n",
      "Model weights saved in test-translation/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-16000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-18000\n",
      "Configuration saved in test-translation/checkpoint-18000/config.json\n",
      "Model weights saved in test-translation/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-16500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-18500\n",
      "Configuration saved in test-translation/checkpoint-18500/config.json\n",
      "Model weights saved in test-translation/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-17000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-19000\n",
      "Configuration saved in test-translation/checkpoint-19000/config.json\n",
      "Model weights saved in test-translation/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-17500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 44.0605, 'gen_len': 28.3505}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-19500\n",
      "Configuration saved in test-translation/checkpoint-19500/config.json\n",
      "Model weights saved in test-translation/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-18000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-20000\n",
      "Configuration saved in test-translation/checkpoint-20000/config.json\n",
      "Model weights saved in test-translation/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-18500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-20500\n",
      "Configuration saved in test-translation/checkpoint-20500/config.json\n",
      "Model weights saved in test-translation/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-19000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-21000\n",
      "Configuration saved in test-translation/checkpoint-21000/config.json\n",
      "Model weights saved in test-translation/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-19500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-21500\n",
      "Configuration saved in test-translation/checkpoint-21500/config.json\n",
      "Model weights saved in test-translation/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-20000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 44.235, 'gen_len': 28.3122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-translation/checkpoint-22000\n",
      "Configuration saved in test-translation/checkpoint-22000/config.json\n",
      "Model weights saved in test-translation/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-20500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-22500\n",
      "Configuration saved in test-translation/checkpoint-22500/config.json\n",
      "Model weights saved in test-translation/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-21000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-23000\n",
      "Configuration saved in test-translation/checkpoint-23000/config.json\n",
      "Model weights saved in test-translation/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-21500] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-23500\n",
      "Configuration saved in test-translation/checkpoint-23500/config.json\n",
      "Model weights saved in test-translation/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-22000] due to args.save_total_limit\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test-translation/checkpoint-24000\n",
      "Configuration saved in test-translation/checkpoint-24000/config.json\n",
      "Model weights saved in test-translation/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in test-translation/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in test-translation/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-translation/checkpoint-22500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: text. If text are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17066\n",
      "  Batch size = 64\n",
      "/home/ma-user/work/anaconda3/envs/yzl_py37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(decoded_preds)= <class 'list'>\n",
      "type(decoded_labels)= <class 'list'>\n",
      "result is as follow============================\n",
      "{'bleu': 44.3371, 'gen_len': 28.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24000, training_loss=0.3073067795435588, metrics={'train_runtime': 9196.9589, 'train_samples_per_second': 166.995, 'train_steps_per_second': 2.61, 'total_flos': 5799969455210496.0, 'train_loss': 0.3073067795435588, 'epoch': 10.0})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from transformers import Seq2SeqTrainer\n",
    "trainer=Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"], # 这里要改成自己的训练集\n",
    "    eval_dataset=tokenized_datasets[\"validation\"], # 这里要改成自己的验证集\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f5cd1de15926e82fa541d8a97e733fb93372e8786ef826141c917c29b3895d8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('yzl_py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93fdebc7ffd4d6b00932dfef327bde760c1853fee847c1c71c95f52227a61dee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
